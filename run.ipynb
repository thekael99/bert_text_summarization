{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"ab6c89459f8f17ad2189cfde781e1db8ea16f167054b1a3268bd5f457fab4c73"},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"orig_nbformat":4,"colab":{"name":"notebook.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WOjFwkjE5Q-e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638969015270,"user_tz":-420,"elapsed":19342,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCwsgExT6Ym368KJa5duD9s3tLkWmGQ5vvY8RUaw=s64","userId":"12069630324860618931"}},"outputId":"76728fde-e328-40a9-e46c-2af693fc3b3f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa1FjlwLBqGy","executionInfo":{"status":"ok","timestamp":1638969080639,"user_tz":-420,"elapsed":310,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCwsgExT6Ym368KJa5duD9s3tLkWmGQ5vvY8RUaw=s64","userId":"12069630324860618931"}},"outputId":"9ac35043-93b5-4123-b91f-346f564e13ed"},"source":["import multiprocessing\n","multiprocessing.cpu_count()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJ7GKleF5d8N","executionInfo":{"status":"ok","timestamp":1638969085666,"user_tz":-420,"elapsed":307,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCwsgExT6Ym368KJa5duD9s3tLkWmGQ5vvY8RUaw=s64","userId":"12069630324860618931"}},"outputId":"384b4e6d-411c-47aa-f163-63050ab4a37a"},"source":["%cd /content/drive/MyDrive/PreSumm"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1yeWPrJsGppwwuZVmjO8QAQhYv4JpS3bU/PreSumm\n"]}]},{"cell_type":"code","metadata":{"id":"PNC7c5xF5VAy","executionInfo":{"status":"ok","timestamp":1638969094974,"user_tz":-420,"elapsed":1932,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCwsgExT6Ym368KJa5duD9s3tLkWmGQ5vvY8RUaw=s64","userId":"12069630324860618931"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"588bcbab-438c-40c9-e7e4-b45876080ad1"},"source":["!pip install -q -r req.txt"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 5.6 MB/s \n","\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory\n","\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"DfwcdQ4w6b_z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638965988399,"user_tz":-420,"elapsed":663706,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyRTlDpL3PK1f5Rby0kJbOBzZcluTf74TcoNFy6g=s64","userId":"04036875492126302021"}},"outputId":"fab221b5-2803-4620-de7c-d4911abb0e16"},"source":["!python src/preprocess.py -mode format_to_bert -raw_path vietnews2_json_data -save_path vietnews_bert_data/bert.pt_data -lower -n_cpus 2 -log_file logs/vietnews_json2pt.log"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a_lst: [('train', 'vietnews2_json_data/vietnews.train.0.json', Namespace(dataset='', log_file='logs/vietnews_json2pt.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=2, pretrained_model='bert', raw_path='vietnews2_json_data', save_path='vietnews_bert_data/bert.pt_data', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), 'vietnews_bert_data/bert.pt_data/vietnews.train.0.bert.pt')]\n","\n","Downloading: 100% 249k/249k [00:00<00:00, 784kB/s]\n","[2021-12-08 12:09:00,078 INFO] Processing vietnews2_json_data/vietnews.train.0.json\n","[2021-12-08 12:15:11,450 INFO] Processed instances 105418\n","[2021-12-08 12:15:11,450 INFO] Saving to vietnews_bert_data/bert.pt_data/vietnews.train.0.bert.pt\n","1it [07:30, 450.58s/it]\n","a_lst: [('valid', 'vietnews2_json_data/vietnews.valid.0.json', Namespace(dataset='', log_file='logs/vietnews_json2pt.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=2, pretrained_model='bert', raw_path='vietnews2_json_data', save_path='vietnews_bert_data/bert.pt_data', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), 'vietnews_bert_data/bert.pt_data/vietnews.valid.0.bert.pt')]\n","\n","0it [00:00, ?it/s][2021-12-08 12:16:30,863 INFO] Processing vietnews2_json_data/vietnews.valid.0.json\n","[2021-12-08 12:17:50,881 INFO] Processed instances 22642\n","[2021-12-08 12:17:50,881 INFO] Saving to vietnews_bert_data/bert.pt_data/vietnews.valid.0.bert.pt\n","1it [01:39, 99.11s/it]\n","a_lst: [('test', 'vietnews2_json_data/vietnews.test.0.json', Namespace(dataset='', log_file='logs/vietnews_json2pt.log', lower=True, map_path='../../data/', max_src_nsents=100, max_src_ntokens_per_sent=200, max_tgt_ntokens=500, min_src_nsents=3, min_src_ntokens_per_sent=5, min_tgt_ntokens=5, mode='format_to_bert', n_cpus=2, pretrained_model='bert', raw_path='vietnews2_json_data', save_path='vietnews_bert_data/bert.pt_data', select_mode='greedy', shard_size=2000, use_bert_basic_tokenizer=False), 'vietnews_bert_data/bert.pt_data/vietnews.test.0.bert.pt')]\n","\n","0it [00:00, ?it/s][2021-12-08 12:18:09,617 INFO] Processing vietnews2_json_data/vietnews.test.0.json\n","[2021-12-08 12:19:29,292 INFO] Processed instances 22644\n","[2021-12-08 12:19:29,293 INFO] Saving to vietnews_bert_data/bert.pt_data/vietnews.test.0.bert.pt\n","1it [01:38, 98.17s/it]\n"]}]},{"cell_type":"code","metadata":{"id":"ghW9SCmNDMwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638966754147,"user_tz":-420,"elapsed":258010,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyRTlDpL3PK1f5Rby0kJbOBzZcluTf74TcoNFy6g=s64","userId":"04036875492126302021"}},"outputId":"c379310e-1bfc-4d0b-ee0d-10c9515bf504"},"source":["!python src/train.py -task abs -mode train -bert_data_path vietnews_bert_data/bert.pt_data/vietnews -dec_dropout 0.2  -model_path models -sep_optim true -lr_bert 0.002 -lr_dec 0.2 -save_checkpoint_steps 100 -batch_size 512 -train_steps 2000 -report_every 100 -accum_count 5 -use_bert_emb true -use_interval true -warmup_steps_bert 20000 -warmup_steps_dec 10000 -max_pos 512 -visible_gpus 0  -log_file logs/abs_bert_vietnews"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2021-12-08 12:28:25,300 INFO] Namespace(accum_count=5, alpha=0.6, batch_size=512, beam_size=5, bert_data_path='vietnews_bert_data/bert.pt_data/vietnews', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='logs/abs_bert_vietnews', lr=1, lr_bert=0.002, lr_dec=0.2, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='models', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=100, report_rouge=True, result_path='../results/cnndm', save_checkpoint_steps=100, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='', test_start_from=-1, text_src='', text_tgt='', train_from='', train_steps=2000, use_bert_emb=True, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=20000, warmup_steps_dec=10000, world_size=1)\n","[2021-12-08 12:28:25,308 INFO] Device ID 0\n","[2021-12-08 12:28:25,308 INFO] Device cuda\n","Some weights of the model checkpoint at FPTAI/vibert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2021-12-08 12:28:36,016 INFO] AbsSummarizer(\n","  (bert): Bert(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(38173, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embedding(38173, 768, padding_idx=0)\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.2, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=768, out_features=38173, bias=True)\n","    (1): LogSoftmax(dim=-1)\n","  )\n",")\n","gpu_rank 0\n","[2021-12-08 12:28:39,704 INFO] * number of parameters: 191982109\n","[2021-12-08 12:28:39,705 INFO] Start training...\n","[2021-12-08 12:29:21,130 INFO] Loading train dataset from vietnews_bert_data/bert.pt_data/vietnews.train.0.bert.pt, number of examples: 105418\n","Traceback (most recent call last):\n","  File \"src/train.py\", line 125, in <module>\n","    train_abs(args, device_id)\n","  File \"/content/drive/My Drive/PreSumm/src/train_abstractive.py\", line 277, in train_abs\n","    train_abs_single(args, device_id)\n","  File \"/content/drive/My Drive/PreSumm/src/train_abstractive.py\", line 336, in train_abs_single\n","    trainer.train(train_iter_fct, args.train_steps)\n","  File \"/content/drive/My Drive/PreSumm/src/models/trainer.py\", line 156, in train\n","    report_stats)\n","  File \"/content/drive/My Drive/PreSumm/src/models/trainer.py\", line 221, in _gradient_accumulation\n","    batch_stats = self.loss.sharded_compute_loss(batch, outputs, self.args.generator_shard_size, normalization)\n","  File \"/content/drive/My Drive/PreSumm/src/models/loss.py\", line 130, in sharded_compute_loss\n","    loss, stats = self._compute_loss(batch, **shard)\n","  File \"/content/drive/My Drive/PreSumm/src/models/loss.py\", line 222, in _compute_loss\n","    stats = self._stats(loss.clone(), scores, gtruth)\n","  File \"/content/drive/My Drive/PreSumm/src/models/loss.py\", line 149, in _stats\n","    .masked_select(non_padding) \\\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","metadata":{"id":"HT_mfof9j1HF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638968885537,"user_tz":-420,"elapsed":18800,"user":{"displayName":"Thắng Bùi Thanh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyRTlDpL3PK1f5Rby0kJbOBzZcluTf74TcoNFy6g=s64","userId":"04036875492126302021"}},"outputId":"ad45555f-a5ec-4152-a0e9-6aa91370b329"},"source":[" !python src/train.py -task abs -mode test -batch_size 512 -test_batch_size 512 -bert_data_path vietnews_bert_data/bert.pt_data/vietnews -log_file logs/abs_bert_vietnews -model_path models -test_from models/model_step_1700.pt -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 20 -alpha 0.95 -min_length 10 -result_path logs/abs_bert_vietnews_test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"src/train.py\", line 10, in <module>\n","    from train_abstractive import validate_abs, train_abs, baseline, test_abs, test_text_abs\n","  File \"/content/drive/My Drive/PreSumm/src/train_abstractive.py\", line 18, in <module>\n","    from models import data_loader, model_builder\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"id":"vC1bDlFgTs-y"},"source":["!python src/train.py -mode test_text -text_src test_text/test_text.txt -task abs -test_from models/model_step_1.pt -result_path results -log_file logs/abs_bert_vietnews"],"execution_count":null,"outputs":[]}]}